# Constants ini file for unit testing DO NOT REMOVE!!
# Example constants ini file, to be parsed from <your project dir>/constants by configparser

[DEFAULT]
# simple string like "mydata"
ID = <your ID>
# Config server at same host to get API and PORT
CONFIG_SERVER = http://localhost:8000
# Any other level will make it less verbose
LOGGING_LEVEL = INFO
# Directory that will be scanned for files to be added to the context
DATA_DIR=<your data dir>
HTML=<your data dir> # please keep the same as DATA_DIR, for legacy reasons
# All the file extentions you want to be part of the context, see LangChain documentation
DATA_GLOB_TXT = *.txt
DATA_GLOB_PDF = *.pdf
DATA_GLOB_DOCX = *.docx
DATA_GLOB_XLSX = *.xlsx
DATA_GLOB_PPTX = *.pptx
# Persistence directory for vectorstore
PERSISTENCE = <your data dir>/vectorstore
# the lower, the more precise. TODO can be changed dynamically
TEMPERATURE = 0.0
# Similir search number of hits
SIMILAR = 4
# Influences the way answers are produced
contextualize_q_system_prompt = Given a chat history and the latest user question 
    which might reference context in the chat history formulate a standalone question 
    which can be understood without the chat history.
# Influences the way answers are produced
system_prompt = You are a chatbot
# depending on your data
chunk_size=80    
# idem
chunk_overlap=10  
# score threshold
score=0.1
# search type: similarity_score_threshold or mmd or similarity 
search_type=similarity_score_threshold

[FLASK]
# any unused port, will run the Flask server
PORT = <your port no>
# Set to True if you want to debug
DEBUG = False
# max files size in MB for upload
MAX_MB_SIZE = 512

[LLMS]
# Possible LLMs
LLMS = OPENAI,GROQ,OLLAMA,AZURE

# LLM to be used
#USE_LLM = OLLAMA
USE_LLM = OPENAI
#USE_LLM = AZURE
#USE_LLM = GROQ
# The LLM to be used as listed in OpenAI

[LLMS.OPENAI]
MODELTEXT = gpt-4o
EMBEDDING_MODEL = text-embedding-3-small 

[LLMS.AZURE]
azure_openai_model_endpoint = https://chat-interactions-proxy-8.openai.azure.com/openai/deployments/gpt-4o
azure_ai_model_endpoint = https://ai-rag410862013562.services.ai.azure.com/models/chat/completions/?api-version=2024-05-01-preview
azure_openai_embedding_endpoint = https://chat-interactions-proxy-8.openai.azure.com/openai/deployments/text-embedding-3-large
modeltext = gpt-4o
embedding_model = text-embedding-3-large
models_openai = gpt-4o
models_ai = DeepSeek-R1, Llama-3.2-11B-Vision-Instruct
embeddings = text-embedding-3-large, text-embedding-3-small

[LLMS.OLLAMA]
MODELTEXT = tinyllama
# Embeddings are used from OPENAI
EMBEDDING_MODEL = text-embedding-3-small

[LLMS.GROQ]
MODELTEXT = gemma2-9b-it
# Embeddings are used from OPENAI
EMBEDDING_MODEL = text-embedding-3-small
