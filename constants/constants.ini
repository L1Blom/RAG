# Constants ini file for unit testing DO NOT REMOVE!!
# Example constants ini file, to be parsed from <your project dir>/constants by configparser

[DEFAULT]
# simple string like "mydata"
ID = <your ID>
# Config server at same host to get API and PORT
CONFIG_SERVER = http://localhost:8000
# Any other level will make it less verbose
LOGGING_LEVEL = INFO
# Directory that will be scanned for files to be added to the context
DATA_DIR=<your data dir>
HTML=<your data dir> # please keep the same as DATA_DIR, for legacy reasons
# All the file extentions you want to be part of the context, see LangChain documentation
DATA_GLOB_TXT = *.txt
DATA_GLOB_PDF = *.pdf
DATA_GLOB_DOCX = *.docx
DATA_GLOB_XLSX = *.xlsx
DATA_GLOB_PPTX = *.pptx
# Persistence directory for vectorstore
PERSISTENCE = <your data dir>/vectorstore
# the lower, the more precise. TODO can be changed dynamically
TEMPERATURE = 0.0
# Similir search number of hits
SIMILAR = 4
# Max tokens to be sued by LLM
max_tokens = 4096
# Influences the way answers are produced
contextualize_q_system_prompt = Given a chat history and the latest user question 
    which might reference context in the chat history formulate a standalone question 
    which can be understood without the chat history.
# Influences the way answers are produced
system_prompt = You are a chatbot
# depending on your data
chunk_size=80    
# idem
chunk_overlap=10  
# score threshold
score=0.1
# search type: similarity_score_threshold or mmd or similarity 
search_type=similarity_score_threshold

[FLASK]
# any unused port, will run the Flask server
PORT = <your port no>
# Set to True if you want to debug
DEBUG = False
# max files size in MB for upload
MAX_MB_SIZE = 512

[LLMS]
# Possible LLMs
LLMS = OPENAI,GROQ,OLLAMA,AZURE

# LLM to be used
#USE_LLM = OLLAMA
USE_LLM = OPENAI
#USE_LLM = AZURE
#USE_LLM = GROQ
# The LLM to be used as listed in OpenAI

[LLMS.OPENAI]
MODELTEXT = gpt-4o
EMBEDDING_MODEL = text-embedding-3-small 

[LLMS.AZURE]
modeltext = gpt-4o
embedding_model = text-embedding-3-large

[LLMS.AZURE.OPENAI]
model_endpoint = https://chat-interactions-proxy-8.openai.azure.com/openai/deployments/
embedding_endpoint = https://chat-interactions-proxy-8.openai.azure.com/openai/deployments/
model_api_version = 2025-01-01-preview
embedding_api_version = 2024-12-01-preview
models = gpt-4o
embeddings = text-embedding-3-large,text-embedding-3-small

[LLMS.AZURE.AI]
model_endpoint = https://ai-rag410862013562.services.ai.azure.com/models/
model_api_version = 2024-05-01-preview
embedding_api_version = 2024-05-01-preview
models = DeepSeek-R1,Llama-3.2-11B-Vision-Instruct,Llama-3.2-90B-Vision-Instruct

[LLMS.OLLAMA]
MODELTEXT = tinyllama
# Embeddings are used from OPENAI
EMBEDDING_MODEL = text-embedding-3-small

[LLMS.GROQ]
MODELTEXT = gemma2-9b-it
# Embeddings are used from OPENAI
EMBEDDING_MODEL = text-embedding-3-small
