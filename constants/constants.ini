# Constants ini file for unit testing DO NOT REMOVE!!
# Example constants ini file, to be parsed from <your project dir>/constants by configparser

[DEFAULT]
# simple string like "mydata"
ID = <your ID>
# Any other level will make it less verbose
LOGGING_LEVEL = INFO
# Directory that will be scanned for files to be added to the context
DATA_DIR=<your data dir>
# All the file extentions you want to be part of the context, see LangChain documentation
DATA_GLOB_TXT = *.txt
DATA_GLOB_PDF = *.pdf
# Persistence directory for vectorstore
PERSISTENCE = <your data dir>/vectorstore
# Where the HTML files reside
HTML = <your data dir>/html
# the lower, the more precise. TODO can be changed dynamically
TEMPERATURE = 0.0
# Similir search number of hits
SIMILAR = 4
# Influences the way answers are produced
contextualize_q_system_prompt = Given a chat history and the latest user question 
    which might reference context in the chat history formulate a standalone question 
    which can be understood without the chat history.
# Influences the way answers are produced
system_prompt = You are a chatbot
# depending on your data
chunk_size=80    
# idem
chunk_overlap=10  

[FLASK]
# any unused port, will run the Flask server
PORT = 7000
# Set to True if you want to debug
DEBUG = False
# max files size in MB for upload
MAX_MB_SIZE = 16


[LLMS]
# Possible LLMs
LLMS = OPENAI,GROQ,OLLAMA

# LLM to be used
#USE_LLM = OLLAMA
USE_LLM = OPENAI
#USE_LLM = GROQ
# The LLM to be used as listed in OpenAI

[LLMS.OPENAI]
MODELTEXT = gpt-4o
EMBEDDING_MODEL = text-embedding-3-small

[LLMS.OLLAMA]
MODELTEXT = tinyllama
EMBEDDING_MODEL = text-embedding-3-small

[LLMS.GROQ]
MODELTEXT = gemma2-9b-it
EMBEDDING_MODEL = text-embedding-3-small
