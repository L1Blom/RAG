{"test": {"project": "test", "port": "5000", "description": "Test project", "provider": "AZURE", "llm": "gpt-4o", "status": "up", "timestamp": "2025-04-07 20:52:55"}, "azure": {"project": "azure", "port": "5002", "description": "Azure documenten lokaal", "provider": "AZURE", "llm": "DeepSeek-R1", "status": "up", "timestamp": "2025-04-07 20:46:41", "pid": 1321367, "globals": {"Chain": "bound=RunnableBinding(bound=RunnableBinding(bound=RunnableAssign(mapper={\n  chat_history: RunnableBinding(bound=RunnableLambda(_enter_history), kwargs={}, config={'run_name': 'load_history'}, config_factories=[])\n}), kwargs={}, config={'run_name': 'insert_history'}, config_factories=[])\n| RunnableBinding(bound=RunnableLambda(_call_runnable_sync), kwargs={}, config={'run_name': 'check_sync_or_async'}, config_factories=[]), kwargs={}, config={'run_name': 'RunnableWithMessageHistory'}, config_factories=[]) kwargs={} config={} config_factories=[] get_session_history=<function get_session_history at 0x7ffeeabae2a0> input_messages_key='input' output_messages_key='answer' history_messages_key='chat_history' history_factory_config=[ConfigurableFieldSpec(id='session_id', annotation=<class 'str'>, name='Session ID', description='Unique identifier for a session.', default='', is_shared=True, dependencies=None)]", "ChunkOverlap": "20", "ChunkSize": "300", "Embedding": "text-embedding-3-large", "LLM": "endpoint='https://ai-rag410862013562.services.ai.azure.com/models/' credential='6jUfdi1NPhyURZJZzbOKwDKhlJJvHO1s5NRAWGutmBYzGQes3eQ4JQQJ99BAAC5RqLJXJ3w3AAAAACOG7fXX' api_version='2024-05-01-preview' model_name='DeepSeek-R1' max_tokens=4096 temperature=0.1 client_kwargs={'logging_enable': True}", "ModelText": "DeepSeek-R1", "NoChunks": "42", "Project": "azure", "Prompt": "You are a chatbot", "Score": "0.1", "Session": "a5dc502f-8ca6-4790-94bd-fce2ce2f29a5", "Similar": "4", "Store": "{}", "SystemPrompt": "You are a chatbot", "Temperature": "0.1", "Tokens": "4096.0", "USE_LLM": "AZURE", "VectorStore": "<langchain_chroma.vectorstores.Chroma object at 0x7ffeebaf5a10>", "timestamp": "2025-04-01 15:38:38"}}, "centric": {"project": "centric", "port": "5001", "description": "Azure documenten", "provider": "AZURE", "llm": "Llama-3.2-90B-Vision-Instruct", "status": "up", "timestamp": "2025-04-07 20:46:42", "globals": {"Chain": "bound=RunnableBinding(bound=RunnableBinding(bound=RunnableAssign(mapper={\n  chat_history: RunnableBinding(bound=RunnableLambda(_enter_history), kwargs={}, config={'run_name': 'load_history'}, config_factories=[])\n}), kwargs={}, config={'run_name': 'insert_history'}, config_factories=[])\n| RunnableBinding(bound=RunnableLambda(_call_runnable_sync), kwargs={}, config={'run_name': 'check_sync_or_async'}, config_factories=[]), kwargs={}, config={'run_name': 'RunnableWithMessageHistory'}, config_factories=[]) kwargs={} config={} config_factories=[] get_session_history=<function get_session_history at 0x7fff998822a0> input_messages_key='input' output_messages_key='answer' history_messages_key='chat_history' history_factory_config=[ConfigurableFieldSpec(id='session_id', annotation=<class 'str'>, name='Session ID', description='Unique identifier for a session.', default='', is_shared=True, dependencies=None)]", "ChunkOverlap": "10", "ChunkSize": "80", "Embedding": "text-embedding-3-large", "LLM": "endpoint='https://ai-rag410862013562.services.ai.azure.com/models/' credential='6jUfdi1NPhyURZJZzbOKwDKhlJJvHO1s5NRAWGutmBYzGQes3eQ4JQQJ99BAAC5RqLJXJ3w3AAAAACOG7fXX' api_version='2024-05-01-preview' model_name='Llama-3.2-90B-Vision-Instruct' max_tokens=4096 temperature=0.0 client_kwargs={'logging_enable': True}", "ModelText": "Llama-3.2-90B-Vision-Instruct", "NoChunks": "42", "Project": "centric", "Prompt": "You are a chatbot", "Score": "0.1", "Session": "1f63774c-e27f-4a72-9e90-36efc7a14db0", "Similar": "4", "Store": "{}", "SystemPrompt": "You are a chatbot", "Temperature": "0.0", "Tokens": "4096.0", "USE_LLM": "AZURE", "VectorStore": "<langchain_chroma.vectorstores.Chroma object at 0x7fff9976b6d0>", "timestamp": "2025-04-01 15:38:39"}}, "gerco": {"project": "gerco", "port": "5004", "description": "Huwelijk Gerco en Anne-Wil", "provider": "OPENAI", "llm": "gpt-4o", "status": "up", "timestamp": "2025-04-07 20:46:41", "pid": 1330027, "globals": {"Chain": "bound=RunnableBinding(bound=RunnableBinding(bound=RunnableAssign(mapper={\n  chat_history: RunnableBinding(bound=RunnableLambda(_enter_history), kwargs={}, config={'run_name': 'load_history'}, config_factories=[])\n}), kwargs={}, config={'run_name': 'insert_history'}, config_factories=[])\n| RunnableBinding(bound=RunnableLambda(_call_runnable_sync), kwargs={}, config={'run_name': 'check_sync_or_async'}, config_factories=[]), kwargs={}, config={'run_name': 'RunnableWithMessageHistory'}, config_factories=[]) kwargs={} config={} config_factories=[] get_session_history=<function get_session_history at 0x7ffebaba7ba0> input_messages_key='input' output_messages_key='answer' history_messages_key='chat_history' history_factory_config=[ConfigurableFieldSpec(id='session_id', annotation=<class 'str'>, name='Session ID', description='Unique identifier for a session.', default='', is_shared=True, dependencies=None)]", "ChunkOverlap": "10", "ChunkSize": "80", "Embedding": "text-embedding-3-large", "LLM": "client=<openai.resources.chat.completions.Completions object at 0x7ffebacc9a90> async_client=<openai.resources.chat.completions.AsyncCompletions object at 0x7ffebabcabd0> root_client=<openai.OpenAI object at 0x7ffebab87e90> root_async_client=<openai.AsyncOpenAI object at 0x7ffebb1dc710> model_name='gpt-4o' temperature=0.0 model_kwargs={} openai_api_key=SecretStr('**********')", "ModelText": "gpt-4o", "NoChunks": "55", "Project": "gerco", "Prompt": "Vandaag ben je de assistent van Gerco, die trouwt met Anne-Wil. Geef antwoord op vragen over de bruiloft op een feestelijke manier!", "Score": "0.1", "Session": "8cb68c01-8d6a-4263-8183-05a472f772be", "Similar": "4", "Store": "{}", "SystemPrompt": "Vandaag ben je de assistent van Gerco, die trouwt met Anne-Wil. Geef antwoord op vragen over de bruiloft op een feestelijke manier!", "Temperature": "0.0", "Tokens": "4096.0", "USE_LLM": "OPENAI", "VectorStore": "<langchain_chroma.vectorstores.Chroma object at 0x7ffeba881290>", "timestamp": "2025-04-01 15:38:39"}}}